{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Card Payment Default - Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will follow the example described in this AWS Blog: https://aws.amazon.com/es/blogs/machine-learning/simplify-machine-learning-with-xgboost-and-amazon-sagemaker/\n",
    "\n",
    "First, we will load some libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a few variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon S3 location: s3://sagemaker-eu-west-1-889960878219/sagemaker/xgboost_credit_risk/\n",
      "AWS IAM role: arn:aws:iam::889960878219:role/service-role/AmazonSageMaker-ExecutionRole-20180920T165537\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/xgboost_credit_risk'\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"Amazon S3 location: s3://{}/{}/\".format(bucket,prefix))\n",
    "print(\"AWS IAM role:\", role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a sample dataset from the University of California Irvine (UCI)'s Machine Learning repository, called: “default of credit card clients” https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "Let us download the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-13 22:59:41--  https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5539328 (5.3M) [application/x-httpd-php]\n",
      "Saving to: ‘default of credit card clients.xls’\n",
      "\n",
      "default of credit c 100%[===================>]   5.28M  3.79MB/s    in 1.4s    \n",
      "\n",
      "2021-03-13 22:59:43 (3.79 MB/s) - ‘default of credit card clients.xls’ saved [5539328/5539328]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the dataset file into a Pandas dataframe and visualize it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>...</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>LIMIT_BAL</td>\n",
       "      <td>SEX</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>MARRIAGE</td>\n",
       "      <td>AGE</td>\n",
       "      <td>PAY_0</td>\n",
       "      <td>...</td>\n",
       "      <td>PAY_AMT1</td>\n",
       "      <td>PAY_AMT2</td>\n",
       "      <td>PAY_AMT3</td>\n",
       "      <td>PAY_AMT4</td>\n",
       "      <td>PAY_AMT5</td>\n",
       "      <td>PAY_AMT6</td>\n",
       "      <td>default payment next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30001 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         X1   X2         X3        X4   X5     X6  ...  \\\n",
       "0             ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  ...   \n",
       "1              1      20000    2          2         1   24      2  ...   \n",
       "2              2     120000    2          2         2   26     -1  ...   \n",
       "3              3      90000    2          2         2   34      0  ...   \n",
       "...          ...        ...  ...        ...       ...  ...    ...  ...   \n",
       "29997      29997     150000    1          3         2   43     -1  ...   \n",
       "29998      29998      30000    1          2         2   37      4  ...   \n",
       "29999      29999      80000    1          3         1   41      1  ...   \n",
       "30000      30000      50000    1          2         1   46      0  ...   \n",
       "\n",
       "            X18       X19       X20       X21       X22       X23  \\\n",
       "0      PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6   \n",
       "1             0       689         0         0         0         0   \n",
       "2             0      1000      1000      1000         0      2000   \n",
       "3          1518      1500      1000      1000      1000      5000   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "29997      1837      3526      8998       129         0         0   \n",
       "29998         0         0     22000      4200      2000      3100   \n",
       "29999     85900      3409      1178      1926     52964      1804   \n",
       "30000      2078      1800      1430      1000      1000      1000   \n",
       "\n",
       "                                Y  \n",
       "0      default payment next month  \n",
       "1                               1  \n",
       "2                               1  \n",
       "3                               0  \n",
       "...                           ...  \n",
       "29997                           0  \n",
       "29998                           1  \n",
       "29999                           1  \n",
       "30000                           1  \n",
       "\n",
       "[30001 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel('default of credit card clients.xls')\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove the unnamed rows, and split the daframe into Training and Validation datasets, with a 70% and 10% of rows for each..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Unnamed: 0', axis=1)\n",
    "dataset = pd.concat([dataset['Y'], dataset.drop(['Y'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(dataset.sample(frac=1, random_state=1729), [int(0.7 * len(dataset)), int(0.9 * len(dataset))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload the train and validation datasets to our Amazon S3 storage..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define our model estimator for the training, in this case by relying on the Amazon SageMaker SDK and pre-defined container image for the XGBoost algorithm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'}\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the training job..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 23:00:18 Starting - Starting the training job...\n",
      "2021-03-13 23:00:42 Starting - Launching requested ML instancesProfilerReport-1615676417: InProgress\n",
      "......\n",
      "2021-03-13 23:01:43 Starting - Preparing the instances for training......\n",
      "2021-03-13 23:02:44 Downloading - Downloading input data...\n",
      "2021-03-13 23:03:06 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-03-13:23:03:27:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-03-13:23:03:27:INFO] File size need to be processed in the node: 2.32mb. Available memory size in the node: 8440.08mb\u001b[0m\n",
      "\u001b[34m[2021-03-13:23:03:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:03:27] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:03:27] 21000x23 matrix with 483000 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-03-13:23:03:27:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:03:27] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:03:27] 6000x23 matrix with 138000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.173619#011validation-error:0.181\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.173143#011validation-error:0.176667\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.172857#011validation-error:0.176167\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.17119#011validation-error:0.176333\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.170143#011validation-error:0.175667\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.169381#011validation-error:0.176833\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.169#011validation-error:0.176667\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.168619#011validation-error:0.177167\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.168286#011validation-error:0.177333\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.168095#011validation-error:0.176167\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.168143#011validation-error:0.177833\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.16781#011validation-error:0.177833\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.167#011validation-error:0.178667\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.166667#011validation-error:0.177167\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.166095#011validation-error:0.177667\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.16581#011validation-error:0.177833\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.165714#011validation-error:0.178667\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.164571#011validation-error:0.178333\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.164476#011validation-error:0.179167\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.164#011validation-error:0.179667\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.163238#011validation-error:0.1795\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.163286#011validation-error:0.179833\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.162571#011validation-error:0.179333\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.16219#011validation-error:0.178333\u001b[0m\n",
      "\u001b[34m[23:03:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.161762#011validation-error:0.178833\u001b[0m\n",
      "\n",
      "2021-03-13 23:03:44 Uploading - Uploading generated training model\n",
      "2021-03-13 23:03:44 Completed - Training job completed\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n"
     ]
    }
   ],
   "source": [
    "xgb.set_hyperparameters(eta=0.1, objective='binary:logistic', num_round=25) \n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is now trained, with the resulting artifacts stored in Amazon S3, so we are ready for deploying an Amazon SageMaker Endnpoint for performing real-time predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.m4.xlarge',\n",
    "    serializer = CSVSerializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test our model with a few predictions using our testing dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10145303, 0.29316297, 0.70782304, ..., 0.15233986, 0.38610485,\n",
       "       0.10773233])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.to_numpy()[:,1:])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting array is showing the probability for each customer to be in default for their credit card payments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
